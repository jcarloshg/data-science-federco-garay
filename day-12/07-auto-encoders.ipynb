{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595f238e",
   "metadata": {},
   "source": [
    "# first steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca23475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0rc0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.74.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jose/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jose/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jose/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jose/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jose/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/jose/anaconda3/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/jose/anaconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/jose/anaconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jose/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jose/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jose/anaconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.20.0rc0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.8/620.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.74.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.11.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (414 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt_einsum, ml_dtypes, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [tensorflow]37m━━\u001b[0m \u001b[32m15/16\u001b[0m [tensorflow]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 grpcio-1.74.0 keras-3.11.1 libclang-18.1.1 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0rc0 termcolor-3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 15:04:32.297276: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-10 15:04:32.337054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-10 15:04:33.396859: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0-rc0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b310489",
   "metadata": {},
   "source": [
    "# the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdf7acfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number zero:\n",
      " [[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "X: [[0.     0.     0.3125 ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.625  0.     0.    ]\n",
      " [0.     0.     0.     ... 1.     0.5625 0.    ]\n",
      " ...\n",
      " [0.     0.     0.0625 ... 0.375  0.     0.    ]\n",
      " [0.     0.     0.125  ... 0.75   0.     0.    ]\n",
      " [0.     0.     0.625  ... 0.75   0.0625 0.    ]]\n",
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.7037 - val_loss: 0.6821\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6701 - val_loss: 0.6506\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6390 - val_loss: 0.6204\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6088 - val_loss: 0.5904\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5788 - val_loss: 0.5606\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5489 - val_loss: 0.5315\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5203 - val_loss: 0.5045\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4942 - val_loss: 0.4807\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4718 - val_loss: 0.4611\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4536 - val_loss: 0.4455\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4394 - val_loss: 0.4334\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4286 - val_loss: 0.4242\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4203 - val_loss: 0.4169\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4138 - val_loss: 0.4110\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4084 - val_loss: 0.4060\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4036 - val_loss: 0.4014\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3992 - val_loss: 0.3971\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3949 - val_loss: 0.3929\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3907 - val_loss: 0.3887\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3865 - val_loss: 0.3846\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3824 - val_loss: 0.3807\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3784 - val_loss: 0.3768\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3745 - val_loss: 0.3730\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3706 - val_loss: 0.3693\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3668 - val_loss: 0.3657\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3631 - val_loss: 0.3623\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3595 - val_loss: 0.3589\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3561 - val_loss: 0.3556\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3528 - val_loss: 0.3524\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3496 - val_loss: 0.3494\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3465 - val_loss: 0.3465\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3435 - val_loss: 0.3436\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3406 - val_loss: 0.3409\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3379 - val_loss: 0.3383\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3352 - val_loss: 0.3358\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3327 - val_loss: 0.3334\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3303 - val_loss: 0.3312\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3280 - val_loss: 0.3292\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3259 - val_loss: 0.3270\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3238 - val_loss: 0.3251\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3219 - val_loss: 0.3232\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3200 - val_loss: 0.3216\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3183 - val_loss: 0.3198\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3166 - val_loss: 0.3182\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3150 - val_loss: 0.3167\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3134 - val_loss: 0.3151\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3119 - val_loss: 0.3137\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3105 - val_loss: 0.3123\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3092 - val_loss: 0.3110\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3079 - val_loss: 0.3097\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3066 - val_loss: 0.3085\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3054 - val_loss: 0.3073\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3042 - val_loss: 0.3061\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3030 - val_loss: 0.3050\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3019 - val_loss: 0.3040\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3008 - val_loss: 0.3028\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2998 - val_loss: 0.3018\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2988 - val_loss: 0.3008\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2978 - val_loss: 0.2998\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2968 - val_loss: 0.2988\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2958 - val_loss: 0.2979\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2949 - val_loss: 0.2970\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2940 - val_loss: 0.2960\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2931 - val_loss: 0.2952\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2922 - val_loss: 0.2943\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2913 - val_loss: 0.2934\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2905 - val_loss: 0.2925\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2897 - val_loss: 0.2917\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2888 - val_loss: 0.2909\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2880 - val_loss: 0.2901\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2872 - val_loss: 0.2893\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2865 - val_loss: 0.2885\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2857 - val_loss: 0.2877\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2850 - val_loss: 0.2869\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2842 - val_loss: 0.2862\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2835 - val_loss: 0.2855\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2828 - val_loss: 0.2848\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2821 - val_loss: 0.2840\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2814 - val_loss: 0.2834\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2807 - val_loss: 0.2827\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2801 - val_loss: 0.2820\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2794 - val_loss: 0.2814\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2788 - val_loss: 0.2807\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2781 - val_loss: 0.2800\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2775 - val_loss: 0.2795\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2769 - val_loss: 0.2789\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2763 - val_loss: 0.2783\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2757 - val_loss: 0.2777\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2752 - val_loss: 0.2771\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2746 - val_loss: 0.2765\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2740 - val_loss: 0.2760\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2735 - val_loss: 0.2755\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2730 - val_loss: 0.2749\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2725 - val_loss: 0.2743\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2719 - val_loss: 0.2739\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2714 - val_loss: 0.2734\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2710 - val_loss: 0.2729\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2705 - val_loss: 0.2724\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2700 - val_loss: 0.2719\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2695 - val_loss: 0.2714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b36bda08050>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "number_zero = digits[\"data\"][0]\n",
    "print(f\"Number zero:\\n {number_zero.reshape(8, 8)}\")\n",
    "# plt.imshow(number_zero.reshape(8, 8))\n",
    "# plt.imshow(digits.images[6])\n",
    "\n",
    "X = digits.data\n",
    "X = X / 16.0  # Normalizar los datos\n",
    "print(f\"X: {X}\")\n",
    "\n",
    "x_train, x_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "image_input = Input(shape=(64,))\n",
    "# rectify, linear, units\n",
    "codification = Dense(32, activation='relu')(image_input)\n",
    "decodification = Dense(64, activation='sigmoid')(codification)\n",
    "autoencoder = Model(inputs=image_input, outputs=decodification)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "# Train the autoencoder using the training data.\n",
    "# The same data is used as input and output because the goal is to reconstruct the input.\n",
    "# epochs=100: number of training epochs\n",
    "# batch_size=256: \n",
    "#   - batch size for each gradient update\n",
    "#   - 256 training items per iteration\n",
    "# shuffle=True: shuffle the data before each epoch\n",
    "# validation_data=(x_test, x_test): use the test data to validate the reconstruction\n",
    "autoencoder.fit(x_train, x_train, epochs=100, batch_size=256, shuffle=True, validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3675afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAEKCAYAAABOuxyuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJ35JREFUeJzt3Xt81NWd//H3zCSTkJCEqyEBwv0mIK2gXCxWraB42bZal1pqWxZrlW0rolu17u+ndlXsekNbtS2trK5W3G6ttpUuRn+V6lpUvFJAQVEJknCHJARymfn+/qBQ8XMGZpKT27ev5+PBQ/j4PfM9nznf7+STmXPORIIgCAQAAOBBtL07AAAAwoPCAgAAeENhAQAAvKGwAAAA3lBYAAAAbygsAACANxQWAADAGwoLAADgDYUFAADwhsICAAB4k9WcRvfdd59uu+02VVZWavTo0Vq4cKGmTp2aVttkMqnNmzeroKBAkUikOaf3ZtGiRbrnnnu0ZcsWjRw5UrfeequmTJkiSQqCQDU1NSotLVU0auuvjpSHlDqXsOQhMSbtpbl5SOHJJSx5SB0rF+73AzpaLqmkk8vBAzOyZMmSIDs7O1i0aFGwZs2a4PLLLw/y8/ODDz/8MK32FRUVgaRO86eiooI8OtifsOQS9jzClEtY8ghTLmHJI2y5BEEQZPyOxZ133qk5c+bo4osvliQtXLhQy5Yt0/33368FCxYctX1BQYEk6TM6S1nKzvT0kqSKayea2Amnr3YeW/W5Wmf8VS1XgbppuMYdir2sZ9VLJRqsY9WkRr2gpYf6+0mZ5tHwZH8Te2rUUhMb9/g/OdsPvuaVlI99pFzKNMxrHhtuPcHEfn3uj0zsjqrT3e0XjjSxvN+tPGoerTEmsVHDTKz3jyuP2u5IXnjnwGNu+fdFivcvUfcLz5EkjfhRrf783gPqXTBUA3tO1PJ1P8o4D1d/JWnSA2+Z2FU93zWxE1/+R2f7vl9dmzKfllxbUuZjMuf1DSb2g9VnZ9TnVNr7Pplygu3z/f3/nG73NfaZr0my19bQua+36pjUnTvBxJbdsTjtfp9x5WwTy/vdyla732PH9HYe3/vRfSaWyfPvcjC31c//VPlFJRp43D9IOpCfjzFxPfeSdO+tP06rf+f/7jvO+JF+nhzJ0cbkoIwKi4aGBr366qu65pprDotPnz5dL774orNNfX296uvrD/27pqbmryfOVlakeYVFLDfXxOJd485jXedIBknVao8GadRh/79n0EfV2nUgFhyIHXxbqqV5JPNzTKywwL6VFHXkliqPtHL560XqKw9X/7o68ojXphiPbNs+K5LdLmMSi9kxSXUdpSvaJVdBU5MaN1aq6JxTFe1yIN+sWKN6FQxR9b4qZf31vJnm4eqvJOV2tbm6rq1Ynru9r2srk1xSySuIpdXvTF87OsJ94rq2XOOU8jFTXVuR7FYdE9c9m0m/Xe2jirXa/R6Luu/heNdEi/JwycrOVTLZpL17NqvfiNMO5eprTFzPneR+zXXJ9OfJUX1iTFKeN5PH3L59uxKJhIqLiw+LFxcXq6qqytlmwYIFKioqOvSnf3/7m3tba1S9AgWK6/AXrLhy1KD9zjYdMQ8p81zCkofUcXNJ1NRJyaRihYdX9TmxfNU32XfQOmoeYRqTsNwnqa6tzjYmYbq2mur3SkFS2bmde0x8atbkzU9WK0EQpKxgrr32Ws2fP//Qv6urqzN6Euu+aD/2WHvJfSY25LFLne2HasURHt3V55blUXXFFGf7N0fbPp+6+vMmNudzf3S2X/SAnRw7/J9Wfuxf6eWSbh47Z0929uOOc/7TxObMm29iWXPdheb2cfY30rLffPxf/scklbVX2rfzFpb8j4ktqDzT2X5Y3lYTW3zm89pc1aT+kn49+beaPKGLJOmE5y9T7RtdlKiPafv47tLH3hVPN4+Ppvc8WkqHjP7zLBNbPfkR57Fn6FNHebS2G5Nj41tMbNawlSa2XF3SfszD+b1PXK9PkvTezJ+k1Ztbto9wxhettPf7qDtqtL+xVpslDVxSp255B37L/dvv4a0zJkOvXmNirteuqv/t62zfZ+5HJhY8fvBv/q+tmimDnO2Xlv3UxFz3SY+HuzrbF7z4vo3pfe1P7JUk5a+qVEH8wK/0vsZk88nu9sOz853xT0p1HU57wn48FV3+elqPmY6MCotevXopFouZdye2bt1q3sU4KCcnRzk57rdg20u2chRRxFSTDao3FfRBHTEPKfNcwpKH1HFz6dUjplhMqtp6+FuvTftrld3FFjMdNY8wjUlY7pN4LE8RRcw7X51tTMJ0bcWjuQfGJFl3WLwz5uJLRh+FxONxjR8/XuXl5YfFy8vLDy0R6gyikagK1E07dfhvRzu1Rd2U/m+FHUFYcglLHpIUj0c0/rgcPfOnw19oajavU/4xA9unU80QpjEJSy7RaEyFXUq0o/bw3547XR4hGQ9JikZiKszurR31FYfFO2MuvmT8Ucj8+fN10UUXacKECZo8ebJ+9rOfaePGjbr0UvdHER1VmYZrtV5WQdBd3dRTm7RB+1Wnvhrc3l3LWFhyCUsekjTvW9309e9s0fhxuZo8PlebXnpSDbW71Guk+yOmjipMYxKWXAb0mqhVm55UYZcSdevSTxuDNzplHmEZD0kakDdOq/Y8q8LsY9QtXtxpx8SXjAuLmTNnaseOHfrBD36gyspKjRkzRkuXLtWAAQNao3+tpk+kvxqDBr2vtarXfnVVoT6lz6hLJL3PrjqSI+XSFDS2d/fSFqYxmfn5Au3cldRNd+5U5dYmxQqSGjL9YuV07aFEg3tCV0cUlmtLCk8uJUXHqrGpTu9tfUH1TbXqqoJOmUeY7veSLsPUGNTrvdqVqk/u7bTXli/Nmrw5d+5czZ0713df2lz/yBD115D27oYXYcklLHlI0mXfKNJl3yiSJJ1w3WXt3JvmC9OYhCWXsp4TVNbzwB4HidXvtHNvmi8s4yFJZXljVJY3RpKU2GIndv89aVZh0ZbSnZE89Iojrf5oOw1F6R8bn/ahiblWf0jS+2f+3MSOPpu/+Xosdm8cc//ioSZWUGxnS1/y7+59Te696YKWdcyjU461L8gzHr/SxFJdW3+661QTe6TMvaFNv489n839DabPXe7ndPlddoXE/rvsJNEnjnPPdm8PDeXudziHZ79hYt/vZcfphdEzne3b+odsqtVPT+y1z/Ud37MrEPJ+85Kz/XDZlTB2F4a28dwau3Jl1B01Jtb1xMDZfuCZO01sc8u7lVL1QLvyTHKvwOl3vntjRZf2eP5H3Go3jJOkM674lInFio8xsYUv/8bEJGn3YLu/RY/lmfXtSPgSMgAA4A2FBQAA8IbCAgAAeENhAQAAvOnwkzevdWyx/MWPLjGx/XdNcrbvutHWTn1/ab/5UfIzk3fQr3Y44+tm7zWx0hV2gt2yMjtJM5XkZz/tjPvcmvWTYqPtBKiFSx8wsTUN7p1Ys9+22/u29qQo16QmSVpc9rSJTbvaTk5N9Tz/4bw7TGzeWe5vp23NHF353XHOwyZ2xfNfdrZ3TRRsbVk39XDGR383va3It53obt8j/bl4XqTaxvrY4XZr8p1ftd8TU/Ci+9rsSKsKDv/qgANc13PtBe5NEj+osWMVl5382dpck4DXr7CT5f/y0zHO9qkmtLemTK4D17HfWvcV57EN3Y78JWItxTsWAADAGwoLAADgDYUFAADwhsICAAB40+Enb7q4JnMN2ej+ErSmz+wxsXfK3F8MM/SKlk+YSrXz36wbrjKx2gF2As0ojXW2X3vJfSa2v0fceWzekTrYQq78XLtVzvncH53t9z1sd4mMT2t5v5pj2oWzTcw18dU1yVaSPr/4X0ysbLV7d8zWtHZBmSNq+zHq2o3O9u2xo2CqCcb9HLv/PbHe7mJZd061s32PxS3qVsbKbnCP94IzzzQx1+vWLeV2MrQkvTDN7kzakSZ0ulx03rPO+GOLP2difWR3HfYl1e7Hrh2bXR654XZn/DuLT2pul9qEa5L5T4f/2HnsvHl2krnP1wHesQAAAN5QWAAAAG8oLAAAgDcUFgAAwJuMJm/ecMMNuvHGGw+LFRcXq6rK/dXBHdmuPyzTnmXlh8U2K0cnR85tpx41z8Y1T2vT24fnEe+EebwXrNb7WntYrDPmIYUnl7DkIYUnl7DkIYUnl7Dk4VPGq0JGjx6tZ5555tC/Y7GY1w59kmtr6M8v/pqJDU0xO9uldEWB3vjLNm0c3E3TfnzGofiWs+qa18k0uLaDdW1KvHP25LQfc3+3qJpyI8rt1kfDzvzWoXj3Ja81p4vNNvSKFSa2XHb1hyRNe+ttE/vN7NO077Vq5X6wq1XySDWbPuqI131xookNy3vO2X7zEa65fBXqeJ186N8RtXwL3VRbk981dYmJXfuIvUfKtqR/j8SKj1G05gN1re+hCd3/4VA8uc29ZX1ruu4tO5v/5uOedB57v+yW7Ae1xpiksnmS3bJ66he/ZWLP3/tTZ/upU04xsbzfHLhe2zKPVFxb+3+/12POY1/4pWOFy1//2xq5pFqp4+K634ffm+881pXzwVVybT0mrn7/YuGdJjY8253LJU88ZWLX32dfMySpz12Zr3TLuLDIyspSnz59Mj5RRxSJRdWl598WZ8Yj7bHwruUi0aiy8woP/TseyWnH3jRfWPKQDryw5ERy27sbLRZRRDmxv90jiYj9vovOIlRjEoI8pPDkEpY8fMm4sFi/fr1KS0uVk5OjiRMn6pZbbtHgwe59ISSpvr5e9fX1h/5dXe1ef94eaiqq9auzlyiWHVOv0b1VGoxQXsSumZc6dh711du16tEbFYllKb93mXKDPqHPQ+rYudSpVn8Kfq+ooipSDw3RmE45JnWJPXpu638oGompKLtYg4OhjEk7yyQPKTy5hCUPqWPn4kNGkzcnTpyohx56SMuWLdOiRYtUVVWlKVOmaMeO1G+PLliwQEVFRYf+9O/fv8Wd9qH36N466fqpOv3u6Zr0/ZO0b+c+rdQf1RDUO4/vqHnk9y7TgJMv1NAzLlHZSReocV/N30UeUsfNpUg9NFon6HhN1SiNV732d8oxKYoXa0zR5zS++7kaXXiK6hN1jEk7yzQPKTy5hCUPqePm4ktGhcWMGTN0/vnna+zYsTr99NP11FMHPqd58MEHU7a59tprtWfPnkN/KioqWtZjT/pO6acBpw1U96E9VHpiqU6783RJUmWKHeE6ah5F/Uep+8Dj1KVHiQr7DteQaXMkhT8PqePm0itSouJIP3WNFKlnpFif1mckdb4x6Z0zQH1yh6ggu6d65vTX8d3PlsSYtKdM85DCk0tY8pA6bi6+tGhL7/z8fI0dO1br169PeUxOTo5ycpr/WfmVv/+qiZWd9FHa7V2TIZeV3e889un8Uu3PyVKsdISCRL0+PtG3pXm4tlvddKqd4Ojaultyb0frmhAqSRUqUp3cn4W3NA/X9tZb5pSaWGMv98bi6+veNTHX1uZSrroeIQ+p5bm4zLjxORNbtHKq89jhWpnWY8YiWeoatHxMaqYMcsa/kP+0id38YWBiG2+Y4mw/6cxVJvb5nu4JW68Pbd0xWffABBO76zg7OfUL+e4+3F1uJwruXNrXeWzXO19stfvE9bqTahtyl9ydDWkdd7RrS2p5Lq5JwwuXPmBi6xrd7T+8r7eJDZjrOI+krlWt99rlmnzput9H/3mWs32/1avTO4/HMam6wn3Pvvkvrp8TdqLmusa9zvZ3f2B/nhzz2r6j9iddLdrHor6+XmvXrlVJSYmv/rSb+vpAtfXbFc9K/blYZ5AMEtqrGuWoc08kSjY1hSIPKTxj0lifDEUeUniur7BcW1J4cglLHi2R0TsWV111lc4991yVlZVp69atuummm1RdXa2vf/3rrdW/VvMvN27XOdPyVdYvS1u3J3Tzwp1qSjapb7fj2rtrGVkXvKneKlWu8tSg/Xpfb6tJjSqR/c2tI9u27LfKH3Gssou6q2lvrXYuL++UeUjhGZMHF3ykCacVqVdptvbsaNJ/37ulU+YhSZXLf6vCwccqu7C7mupqte2lznl9heXakqR3qv9XvXMHKjdaoIbkPm3Yu7JT5hKmMfElo8Ji06ZNuvDCC7V9+3b17t1bkyZN0ooVKzRgQOd7AjdVNmnW3Cpt35lQ754xTTw+V5MGf0Nd4im+Gq+Dqtc+rdJLalS94spRoXrqBJ2mLhH3+uWOqql6tyr/+2El6vYqlpevLv0GdMo8pPCMyY6qRt11xQeq2ZVQYY8sDftUXqfMQ5KaanerYunDSuzbq1iXfOWVdM7rKyzXliTtT+7VW7vL1ZDcr3i0i4qyiztlLmEaE18yKiyWLLGfdXZWj/7E7sVx1jT7WWBHNzYyqb274EXJBXZzlq4ZbHTTkYRlTObfPdDE7h9WaA/sBPqf7bi+mrHxT3sLy7UlSeO6TTexjv7V8C5hGhNf+K4QAADgTYtWhbQF13bRzpnj659N8Qh2FcIJ113mPLLH6r+tskgEKaY4N9OpP7K/HX2/1zv2OMfqD0nq8lU7Y7c99gkdlmd/o1hc/ryJpZqNPOPxK00sk+3YfXKt1PlS0Y9N7I8Pumdmt7VUKwVcz/UrN7tXPrm4ZsFv+bx7S3apdX+jPOVYe0+kWgHi8sfRjq2+R7uPHTT24kN/T+7bL811bxPeHNun2teP9yc/YruWagXC8te99aWltp01xMRcW0UPeexSZ/uyMZUmtu9h9/UVn5Zh5xxcqz8kaWm53XLc9Xrb7/z0Vn+0hYYUn8w/sdcuMrj7g8+ZWHyae8lr3LkUNvXy2EzxjgUAAPCGwgIAAHhDYQEAALxp8zkWQXBgR8AmNUp2c8C0JPftN7G6mvRnHCQabHtJavrYvIomHfj7wf5+UqZ57K+1n7lW5yRtH/a695dvStrP19OZB9JeedQ22pgkJffb574pzfksvnNJNtm+1NY4xsRxnCRFmzkPp7l5uPoruftcne1+/l0Sdfaac11v0uHX3NHy+Pj/S3dMGmrteasd+fnw8deRg3/3dm05XqNcebieeyn9e8K0a4Uxcb1eunJx3dtS6tc0l6iH1+Ag4T6fq8+uvjX3vk6lJWOSSPGcun7edZRcDh7QpioqKgIdeOo6xZ+Kigry6GB/wpJL2PMIUy5hySNMuYQlj7DlEgRBEAmCo5UefiWTSW3evFlBEKisrEwVFRUqLGy9tfHV1dXq379/xucJgkA1NTUqLS1VNGo/MTqYR0FBgWpqapp1jkw1J5ew5CGFJ5e/lzyktr/fJcaEMWFMjqa1XoMPavOPQqLRqPr163fo++cLCwtb/aJu7nmKiopS/r+DeUhSJBJp9jmaI9PzhCUPKTy5/D3kIbXf/d6cczEmrY8xcQvLz8WDmLwJAAC8obAAAADetFthkZOTo+uvvz6t76Tv6OcJSy5hyaOtztEW5yGPjncuxqTjnYsx6VjnafPJmwAAILz4KAQAAHhDYQEAALyhsAAAAN5QWAAAAG8oLAAAgDftVljcd999GjRokHJzczV+/Hg9//zzXh//hhtuUCQSOexPnz59vJ5Dav08pPDkQh6Z4dpKX1jykMKTS1jykMKTS1vl0S6FxWOPPaZ58+bpuuuu0+uvv66pU6dqxowZ2rhxo9fzjB49WpWVlYf+rFq1yuvjt1UeUnhyIY/0cG1lLix5SOHJJSx5SOHJpbXzkKQ2/3bTIAiCE088Mbj00ksPi40cOTK45pprvJ3j+uuvD8aNG+ft8VzaIo8gCE8u5JE+rq3MhCWPIAhPLmHJIwjCk0tb5BEEQdDm71g0NDTo1Vdf1fTp0w+LT58+XS+++KLXc61fv16lpaUaNGiQvvzlL2vDhg3eHrst85DCkwt5HB3XVvOEJQ8pPLmEJQ8pPLm0Zh4HtXlhsX37diUSCRUXFx8WLy4uVlVVlbfzTJw4UQ899JCWLVumRYsWqaqqSlOmTNGOHTu8PH5b5SGFJxfySA/XVubCkocUnlzCkocUnlxaO4+D2vxr0w86+DW3BwVBYGItMWPGjEN/Hzt2rCZPnqwhQ4bowQcf1Pz5872dp7XzkMKTC3lkhmsrfWHJQwpPLmHJQwpPLm2VR5u/Y9GrVy/FYjFThW3dutVUaz7l5+dr7NixWr9+vZfHa688pPDkQh5uXFstF5Y8pPDkEpY8pPDk4juPg9q8sIjH4xo/frzKy8sPi5eXl2vKlCmtdt76+nqtXbtWJSUlXh6vvfKQwpMLebhxbbVcWPKQwpNLWPKQwpOL7zwOafXpoQ5LliwJsrOzg1/84hfBmjVrgnnz5gX5+fnBBx984O0cV155ZfDcc88FGzZsCFasWBGcc845QUFBgddztEUeQRCeXMgjfVxbmQlLHkEQnlzCkkcQhCeXtsgjCIKgXQqLIAiCe++9NxgwYEAQj8eD448/Pli+fLnXx585c2ZQUlISZGdnB6WlpcF5550XrF692us5gqD18wiC8ORCHpnh2kpfWPIIgvDkEpY8giA8ubRVHpEgCAK/74EAAIC/V3xXCAAA8IbCAgAAeENhAQAAvKGwAAAA3lBYAAAAbygsAACANxQWAADAGwoLAADgDYUFAADwhsICAAB4Q2EBAAC8obAAAADeUFgAAABvKCwAAIA3FBYAAMAbCgsAAOANhQUAAPCGwgIAAHhDYQEAALyhsAAAAN5QWAAAAG8oLAAAgDcUFgAAwBsKCwAA4A2FBQAA8IbCAgAAeENhAQAAvKGwAAAA3lBYAAAAbygsAACANxQWAADAGwoLAADgDYUFAADwhsICAAB4Q2EBAAC8obAAAADeUFgAAABvKCwAAIA3FBYAAMAbCgsAAOANhQUAAPCGwgIAAHhDYQEAALyhsAAAAN5QWAAAAG8oLAAAgDcUFgAAwBsKCwAA4A2FBQAA8IbCAgAAeENhAQAAvKGwAAAA3lBYAAAAbygsAACANxQWAADAGwoLAADgDYUFAADwhsICAAB4Q2EBAAC8obAAAADeUFgAAABvKCwAAIA3FBYAAMAbCgsAAOANhQUAAPCGwgIAAHhDYQEAALyhsAAAAN5QWAAAAG8oLAAAgDcUFgAAwBsKCwAA4A2FBQAA8IbCAgAAeENhAQAAvKGwAAAA3lBYAAAAbygsAACANxQWAADAGwoLAADgDYUFAADwhsICAAB4Q2EBAAC8obAAAADeUFgAAABvKCwAAIA3FBYAAMAbCgsAAOANhQUAAPCGwgIAAHhDYQEAALyhsAAAAN5QWAAAAG8oLAAAgDcUFgAAwBsKCwAA4A2FBQAA8IbCAgAAeENhAQAAvKGwAAAA3lBYAAAAbygsAACANxQWAADAGwoLAADgDYUFAADwhsICAAB4Q2EBAAC8obAAAADeUFgAAABvKCwAAIA3FBYAAMAbCgsAAOANhQUAAPCGwgIAAHhDYQEAALyhsAAAAN5QWAAAAG8oLAAAgDcUFgAAwBsKCwAA4A2FBQAA8IbCAgAAeENhAQAAvKGwAAAA3lBYAAAAbygsAACANxQWAADAGwoLAADgDYUFAADwhsICAAB4Q2EBAAC8obAAAADeUFgAAABvKCwAAIA3FBYAAMAbCgsAAOANhQUAAPAmqz1OOi16gQ1GY85jY4PLTKz/L6tM7Jl3Rjrbj/jn90wsUV19lB7+TXnyVyn/nyuPSE6O89h3bzrexB44/34T+0nlqc72O67sb8/16tvOY4PGBhPLNI+svqXOY4c8uc3EvtTjFROrS7qfh/mL55hY2Q9fdh4bNDWZ2JHykFJcW5GI89itcyeb2NTZNpcx+R8525+bv87EfrjtFOex6746yMT+Z/UtzmMldx6x0SOcx97y+4dMrFes0T7mS5c52w+6ZJOJJXbtStm3T2rOmERzc53Hlv3JjtWtJc+a2PlzvutsH/9/b5iY6zpKJdP7JNW1tf6eE03sd+cuNLHesaSzfU0yMLFzFn/PeWzZjX82sfLEfzmPPcj52pUddx5b+e0J9vHn32Zi1350hrP9uh+ONrH8pW84jw0aHK9dR8jFeW0VFDiP/dLL603s3K7250NVwv2zaMW+wSZ2z4NfcB7b73b7mvZ0w6POYw9yXl+TjnMee8ujPzexEdn2Wjr5ta872/eZbV/HE7v2uDuWTJjQ0e553rEAAADeUFgAAABvKCwAAIA37TLHwiWa6/5MvnJ6iYmd3XWlia16apyzveszu1Sfiyqwn2tm7LjhzvC7s+x8iq99eLKJJeXuW9Ht9nP+mjOynce65lhkau337NwWSbq6x1IT++aj9rP7sSfbzzMlqaG7/RwwkuW+DDP5bPxIoinmvZz9zedN7PSC1SY2u/xiZ/u+p9u5DVML7LwLSXo71z0/IhObT+vpjG9NdDWx2ytPMrFZI+z8EUn63wF2/o9273Z3wsc9ImnX+Z9yxp/o+yMTe6fR/v6zZ6D72u8dc3w+7uk6ckmc8mlnfMP5PzWxp+sKTewrb3zJ2X7vXjsHZeDy/e5OeBqT6IC+zviNc+11fs+OSSaWFbWfxUvS/7ntARO76w/jnccGHnJZ9wM7p0OS5hTZ+/27m08xsddvcdwPkuToWo/AfW0FjjkyzbFzVL4zPiDLzqHakrDnfOS4xc72lw+3r9mRl1LMsWgG3rEAAADeUFgAAABvKCwAAIA3FBYAAMAbCgsAAOBNx1kVUujeLW3UrLUm9tIeu4tht3L3bHzF7W5yMUdMymxHzlR2D3fP4n2rwc7o3nL5ABP78Cr343524LsmVptipzwfBj1pZx1L0i3/McseG7XP24zz/uJsv/V5u3tdsr4+w95lJtqzhzN+SY9nTOzMn9ndDUfd487lo5fs48YjKWaJv7HmSF1MS/Ertc74nV+eaWLrvm1Xwhw/YaOzfaSh9VZNpNLY1b36KSdiV3v0iNrrI3uve9Z9xLEqJGjFVWAbznOvTnH513+zq4v6/o/d+VGS5Lgngv3u+8S9d2fmIvXue/4nFZ+15/zXXib24Vl5zvaXzXrOnqur+3VS+1OsfMlAxL04RZVN9v5596KBJlawzb7WSlJQu9eeK8VqxkTgZ1R6ve5eqfGVmXNNrKG7/XnwzTsfd7ZP5tr7JJaqz6nunyPgHQsAAOANhQUAAPCGwgIAAHhDYQEAALzpMJM3lWJb5ytLf2di/7bxXBOrmD3E2T53h52g1fs3LZ9Il0rh+/uc8Zs2nW1iu663E5V+MeoxZ/uKRrud838W2G2bJUm7W741a85K95bcQZn9OvWrn7Rfa3xKF/dEoIfrHRPmIinq2yDFLKwMNQwudsZv32q/oj7/I9u/rf/o3iL4lLw/mNgZy+Y5jx0euLfTzkT0jRQTlIcPNKHrJtqJqc/uHOVsHlRU2mArj0mfcsc5Jf32KjsBcGTcTprbNdI9oayH63WkFXPJ3uN+7Nqkvbd7feNDE9tdbyczS1LRU3ZreWWnmCjqYcKjJKnRPXkzNtsxAT5mX2OKPl3nbO967UsOcN+T2r7jCB1MT9Ze95jkOq6Dbj/fbmJvLHXfJwPvswsJUk3e9PEaLEmRD933SdQxkTTn0/ZrAz6st5NsJSm+xU5kTWb5+4oI3rEAAADeUFgAAABvKCwAAIA3FBYAAMCbDjN5s2HIMc74mLidpPXzwXY3sev+8XT34yZtihu2uyfn5P7u5SN1MS2xN927tu29sLuJ9Si2E3/+efK3ne1/csWPTKyxn53QKUmRik1H6mJaEo7JQZIU+2iLif3r+i+Y2P8daifdStK4m183sXcqhzuPTb5pJ0s1R3zTTmf89VuON7HAsUlnr6+4d6z82uqvm9io293n8jHlMdngnlxXO7Kbib2wZ5iJrf4v93XfN8s+z7EUOyP62J1WkpretxMZJeneWeebmGuSc+OAFLtQ1jkmEHraBdFl6E/c18bUsd8wsdvH/MrEPrrBvi5I0qNrHK9n71Vk1LdMJXbscsajXXJNrO4zdqLg5UPduzz+2xK7M+yQzRucx/rYA3bg72uc8VvOtZPdb+5nX6fWzP6zs/3dz33ZxLLfc0+u9CWxx32/ucakaqLdvbp8y0j34w7rZmJdN3dxH7ubyZsAAKAdUVgAAABvKCwAAIA3FBYAAMAbCgsAAOBNh1kVEq9wz0je4Nhm9sr3LzCxYF6Rs/17M7uZ2IRr3nYeu8O9kCEjyb3u1RRBvZ3FHtlmt5M9JtvOtpakX++eYM+VE3Me64564tgyuXDWbhNbGDnZ2bz493aG8bpvuMdu6Hz3ts2ZSm53r9QofNGuNth0Y5mJrRz5lLP95KsuNbHEuy3fujuVWHf383TC1StN7LerxpnYqF+7V2I0jehvYnv7umeI5z/e8pVTkqTAsbW7pNg6u8oiFrXbEi866UFn+zu6nZL2uRI73NdFJpo2VznjJVfZFV/fuvEiE3t40i+c7becZFeL9F71Toa9y0wkO8WPg/4lJrRxpl3ndFaee9XKz16xaz2CphTrpCIe7vk33M/Tmi/2M7HTb/6Oic0/3m6HL0mxWvsanvCwBfmRpLrnK/7Jrva48KJnTezhdSc422cNsWNd8FY3dydSrEw5Et6xAAAA3lBYAAAAbygsAACANxQWAADAmw4zeTPY6Z68ecFr3zSx3gX2u+SzCuxkKUlq6mcn3Jzd6y3nsQ/nu7c/zUQkx92PujPtZLpdI+zTP+4La5ztV++xE6jir7m3D/exfXRWX3s+SdqzKG5i+x4vtu33uR/3yt4/M7HlPe3205KkiKe6N+ne0jmos50cOHiriT1dl+1s3/1Zuy1xIul+9iOOSa+ZSgyzk88kaWHJQya2L2H7/Mx8ew1K0pzT/2hiSzePdh4bfcp9fWcq1s09KW3tD+327jc5tvDfkejqbL/+e7Z9fIh78tmAq919yEQ07r425IifM+IvJvZinfva7/aee/v29lDt2DL+ic/ebWK/qh3qbF/T304nz1/vfu6jri3ZMxRNcW0lu9lrZsYI+3p7z6pTne0Hb3jfxIKEj1fbI+jRzRn+9bdvM7FEYCe+Dj3OPbn4mjq7db4ed09yjqb4mXYkvGMBAAC8obAAAADeUFgAAABvKCwAAIA3FBYAAMCbDrMqJFFtV3pI0oDv7jax9bfZLX7X/dd/ONtvbLKP+9ml853Hjmh6M3UH05VilnDOdytN7NdDl5jYGeWXO9uP+ne7aiZRuyXDzqUvqHVvTX7JwBUmNvwa249oxL0S4+I3v2ZiI292z9pPRv1s6e3aTl2Sts22290+OOxOE7v42iuc7Qu3pb99d9BktzXOVNZW9/O0usGubrmuT7mJ/Z8v2ZgkXVXxDybW+Eu70keSInG7DX2zpFglk9PdbrM+qyD9bZNPufB2E9uWcP/+dNkY972WiSDhvs7fnl9gYktL7NbrQx+5zNl+6PLX7LlSbE3uS3K/+z7Z18s+f8fFc03slX3u52LPSXZM87b1dB5buMO9OjATkTzbN0ma8yu7Nf85+fbaOuvqMc72yVrHz6hWHpNIjft1OC9iz9svO9/EznvF3tuSNOo6u/otmWqL+2jm7z/wjgUAAPCGwgIAAHhDYQEAALyhsAAAAN5EgtaeEQQAAP5u8I4FAADwhsICAAB4Q2EBAAC8obAAAADeUFgAAABvKCwAAIA3FBYAAMAbCgsAAOANhQUAAPDm/wPHtkFk/i/nMQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(8, 8))\n",
    "    plt.subplot(2, 10, i + 1 + 10)\n",
    "    plt.imshow(autoencoder.predict(x_test[i].reshape(1, 64)).reshape(8, 8))\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
